{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper as hlp\n",
    "import numpy as np\n",
    "from qpixl import cFRQI\n",
    "from qpixl_photoshop import one_image_photoshop, two_image_comb\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit_aer import StatevectorSimulator\n",
    "\n",
    "backend = StatevectorSimulator()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_image_photoshop(img,shape,comp=10, state_to_prob = np.abs):\n",
    "    test = hlp.pad_0(img)\n",
    "    test = hlp.convertToAngles(test)\n",
    "    qc = cFRQI(test,10)\n",
    "    ### INSERT DESIRED GATES HERE\n",
    "    for i in range(1):\n",
    "        qc.cnot(i,i+10)\n",
    "    #################\n",
    "    job = backend.run(qc)\n",
    "    sv = hlp.real(job.result().get_statevector())\n",
    "    img = hlp.decodeQPIXL(sv, state_to_prob = state_to_prob)\n",
    "    img = hlp.reconstruct_img(img, shape)\n",
    "    return img\n",
    "\n",
    "\n",
    "\n",
    "def two_image_comb(img1,img2,shape,comp=10,state_to_prob = np.abs):\n",
    "    img1 = hlp.convertToAngles(pad_0(img1))\n",
    "    img2 = hlp.convertToAngles(pad_0(img2))\n",
    "    qc1 = cFRQI(img1,comp)\n",
    "    qc2 = cFRQI(img2,comp)\n",
    "    big_qc = QuantumCircuit(qc1.width()+qc2.width())\n",
    "    big_qc = big_qc.compose(qc1, qubits=list(range(qc1.width())))\n",
    "    big_qc = big_qc.compose(qc2, qubits=list(range(qc1.width(),qc1.width()*2)))\n",
    "    ### INSERT DESIRED GATES HERE\n",
    "    big_qc.x(range(11,22))\n",
    "    for i in range(11):\n",
    "        big_qc.cnot(i, i+qc1.width())\n",
    "        # Example of CNOT between two images\n",
    "    #########################\n",
    "    job = backend.run(big_qc)\n",
    "    sv = np.real(job.result().get_statevector())\n",
    "    img = hlp.decodeQPIXL(sv, state_to_prob = state_to_prob)#Image 1 is the one that is recovered\n",
    "    img = hlp.reconstruct_img(img, shape)\n",
    "    return img\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07b300163aa49736bc99c2e65c19119dd077db61d3deffc047b36e340452655c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
