{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ede4b480-80e3-4aef-9b23-d9721881fe83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f7155034-fac6-4159-8aeb-5f150c0ac927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /opt/conda/lib/python3.10/site-packages (0.0.post1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e019f2e1-ad01-49a3-b3f7-9477c7458095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.4.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.38.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6e750f82-596d-4031-8035-657f72eaef28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit in /opt/conda/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: qiskit-aer==0.11.2 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.11.2)\n",
      "Requirement already satisfied: qiskit-terra==0.23.2 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.23.2)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.20.1 in /opt/conda/lib/python3.10/site-packages (from qiskit) (0.20.1)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer==0.11.2->qiskit) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer==0.11.2->qiskit) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil~=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (2.8.2)\n",
      "Requirement already satisfied: websocket-client~=1.5.1 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (1.5.1)\n",
      "Requirement already satisfied: requests-ntlm~=1.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (1.1.0)\n",
      "Requirement already satisfied: websockets~=10.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (10.4)\n",
      "Requirement already satisfied: requests~=2.28.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (2.28.2)\n",
      "Requirement already satisfied: urllib3~=1.26.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit) (1.26.14)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (3.11)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (0.3.5.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (5.0.0)\n",
      "Requirement already satisfied: symengine>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (0.9.2)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (5.9.4)\n",
      "Requirement already satisfied: rustworkx>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (0.12.1)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit) (1.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil~=2.8.0->qiskit-ibmq-provider==0.20.1->qiskit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit) (2022.12.7)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=1.3 in /opt/conda/lib/python3.10/site-packages (from requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit) (39.0.1)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra==0.23.2->qiskit) (5.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra==0.23.2->qiskit) (1.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=1.3->requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e76b8882-1ec1-483f-8c77-6a150fd55e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit[machine-learning] in /opt/conda/lib/python3.10/site-packages (0.41.1)\n",
      "Requirement already satisfied: qiskit-aer==0.11.2 in /opt/conda/lib/python3.10/site-packages (from qiskit[machine-learning]) (0.11.2)\n",
      "Requirement already satisfied: qiskit-ibmq-provider==0.20.1 in /opt/conda/lib/python3.10/site-packages (from qiskit[machine-learning]) (0.20.1)\n",
      "Requirement already satisfied: qiskit-terra==0.23.2 in /opt/conda/lib/python3.10/site-packages (from qiskit[machine-learning]) (0.23.2)\n",
      "Requirement already satisfied: qiskit-machine-learning>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from qiskit[machine-learning]) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer==0.11.2->qiskit[machine-learning]) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer==0.11.2->qiskit[machine-learning]) (1.10.1)\n",
      "Requirement already satisfied: urllib3~=1.26.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.26.14)\n",
      "Requirement already satisfied: requests-ntlm~=1.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.1.0)\n",
      "Requirement already satisfied: websocket-client~=1.5.1 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.5.1)\n",
      "Requirement already satisfied: requests~=2.28.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (2.28.2)\n",
      "Requirement already satisfied: python-dateutil~=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (2.8.2)\n",
      "Requirement already satisfied: websockets~=10.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (10.4)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (1.11.1)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (5.0.0)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (0.3.5.1)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (3.11)\n",
      "Requirement already satisfied: rustworkx>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (0.12.1)\n",
      "Requirement already satisfied: symengine>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (0.9.2)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra==0.23.2->qiskit[machine-learning]) (5.9.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning>=0.4.0->qiskit[machine-learning]) (1.2.1)\n",
      "Requirement already satisfied: fastdtw in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning>=0.4.0->qiskit[machine-learning]) (0.3.4)\n",
      "Requirement already satisfied: setuptools>=40.1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-machine-learning>=0.4.0->qiskit[machine-learning]) (67.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil~=2.8.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests~=2.28.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (2022.12.7)\n",
      "Requirement already satisfied: ntlm-auth>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.5.0)\n",
      "Requirement already satisfied: cryptography>=1.3 in /opt/conda/lib/python3.10/site-packages (from requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (39.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->qiskit-machine-learning>=0.4.0->qiskit[machine-learning]) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->qiskit-machine-learning>=0.4.0->qiskit[machine-learning]) (1.2.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra==0.23.2->qiskit[machine-learning]) (5.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra==0.23.2->qiskit[machine-learning]) (1.2.1)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=1.3->requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm~=1.1.0->qiskit-ibmq-provider==0.20.1->qiskit[machine-learning]) (2.21)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit[machine-learning]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aec725b9-78ef-4789-b7bb-49f99e379feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: qiskit-aer-gpu in /opt/conda/lib/python3.10/site-packages (0.11.2)\n",
      "Requirement already satisfied: qiskit-terra>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer-gpu) (0.23.2)\n",
      "Requirement already satisfied: numpy>=1.16.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer-gpu) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-aer-gpu) (1.10.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (2.8.2)\n",
      "Requirement already satisfied: psutil>=5 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (5.9.4)\n",
      "Requirement already satisfied: stevedore>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (5.0.0)\n",
      "Requirement already satisfied: dill>=0.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (0.3.5.1)\n",
      "Requirement already satisfied: symengine>=0.9 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (0.9.2)\n",
      "Requirement already satisfied: rustworkx>=0.12.0 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (0.12.1)\n",
      "Requirement already satisfied: ply>=3.10 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (3.11)\n",
      "Requirement already satisfied: sympy>=1.3 in /opt/conda/lib/python3.10/site-packages (from qiskit-terra>=0.21.0->qiskit-aer-gpu) (1.11.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.0->qiskit-terra>=0.21.0->qiskit-aer-gpu) (1.16.0)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from stevedore>=3.0.0->qiskit-terra>=0.21.0->qiskit-aer-gpu) (5.11.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy>=1.3->qiskit-terra>=0.21.0->qiskit-aer-gpu) (1.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install qiskit-aer-gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae1c772",
   "metadata": {},
   "source": [
    "# Distributed Quantum Image and Signal Encoder\n",
    "\n",
    "In the code below, we will implement a distributed amplitude encoder for encoding images in chunks of size n, which form a bigger image of size N. The number of chunks is determined by N/n, and the number of qubits per chunk is determined by ceil(log2(n)). This approach is useful given it allows us to encode high dimensional data using shallow Parameterized Quantum Circuits (PQCs), and still maintains a high fidelity (78 percent). This approach can be further improved by shallower PQCs which perform amplitude encoding using a lower depth, whilst maintaining the fidelity, which allows us to encode larger chunks for better fidelity. Furthermore, we can load multiple chunks in parallel to have a faster encoding process for the overall image.\n",
    "\n",
    "1) Import dataset\n",
    "\n",
    "2) Pass image to encoder\n",
    "\n",
    "3) Split image to smaller chunks and normalize each chunk\n",
    "\n",
    "4) Encode each chunk using RawFeatureVector (RFV) PQC\n",
    "\n",
    "5) Simulate each chunk to extract the statevector\n",
    "\n",
    "6) Append all chunks classically together and renormalize\n",
    "\n",
    "7) Denormalize the image statevector using RGB_decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24d28c8-813f-427f-ba75-f3ee21eb16c2",
   "metadata": {},
   "source": [
    "First, we will import the necessary packages. For the model, we will be using Qiskit, for plotting we will be using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "73194ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All packages imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Importing standard Qiskit libraries\n",
    "import qiskit\n",
    "from typing import Dict, List\n",
    "from qiskit import QuantumCircuit, transpile, Aer, execute\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.tools.jupyter import *\n",
    "from qiskit.visualization import *\n",
    "from qiskit.providers.aer import QasmSimulator\n",
    "from qiskit_machine_learning.circuit.library import RawFeatureVector\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.quantum_info import Statevector\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit_aer import StatevectorSimulator\n",
    "\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "import sklearn\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "print(\"All packages imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad0feda-feae-497e-aae8-c47f924e4b35",
   "metadata": {},
   "source": [
    "We will load the image and split it into RGB channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e9453413-adc9-4ffa-8e66-e5ef5dda40db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JPEG\n",
      "(1920, 1080)\n",
      "RGB\n"
     ]
    }
   ],
   "source": [
    "Image_ghost = Image.open('Ghost.jpg')\n",
    "Image_ghost_data = np.asarray(Image_ghost)\n",
    "chunk_size = 64\n",
    "\n",
    "red_channel = []\n",
    "green_channel = []\n",
    "blue_channel = []\n",
    "\n",
    "for i in range(len(Image_ghost_data)):\n",
    "    for j in range(len(Image_ghost_data[0])):\n",
    "        red_channel.append(Image_ghost_data[i][j][0])\n",
    "\n",
    "for i in range(len(Image_ghost_data)):\n",
    "    for j in range(len(Image_ghost_data[0])):\n",
    "        green_channel.append(Image_ghost_data[i][j][1])\n",
    "\n",
    "for i in range(len(Image_ghost_data)):\n",
    "    for j in range(len(Image_ghost_data[0])):\n",
    "        blue_channel.append(Image_ghost_data[i][j][2])\n",
    "        \n",
    "\n",
    "red_channel = np.array(red_channel).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "green_channel = np.array(green_channel).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "blue_channel = np.array(blue_channel).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "\n",
    "print(Image_ghost.format)\n",
    "print(Image_ghost.size)\n",
    "print(Image_ghost.mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ec94ef3-d2fc-4795-b319-b3c46931deb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22, 16, 16], dtype=uint8)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image_ghost_data[0][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8a3ceff9-1b82-4182-af5b-646e898aa5b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920, 3)\n"
     ]
    }
   ],
   "source": [
    "Image_ghost_data = np.asarray(Image_ghost)\n",
    "print(Image_ghost_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4c7acc84-6fcb-4fb6-88c6-a2dcd6ba093e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "red_channel_data = np.asarray(red_channel)\n",
    "print(red_channel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ecf1cb01-2468-4b47-98f1-559d393c3ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "blue_channel_data = np.asarray(blue_channel)\n",
    "print(blue_channel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "27d31073-d0b8-422b-a7e8-903e496f9565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "green_channel_data = np.asarray(green_channel)\n",
    "print(green_channel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2f86bd31-175f-4a9c-a336-8d3a814a713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_channel_data_flat = red_channel_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5919f3de-e174-4651-809c-00731edaca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_channel_data_flat = blue_channel_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "deea9f13-a26c-4238-8ede-4a9f3841afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_channel_data_flat = green_channel_data.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e575c3b1-34ed-4185-9728-f825ad8ff039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2073600"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(r_channel_data_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09fdbb5",
   "metadata": {},
   "source": [
    "To see how many qubits we will need for the overall image, we will take the log2 of the image vector. This is essentially to see how many qubits we need to cover all pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "29e4784b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.ceil(np.log2(r_channel_data_flat.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d384fc4-78cc-40d1-b570-69acb15f0f24",
   "metadata": {},
   "source": [
    "In some cases, the number of qubits for the datapoint can support even higher number of pixels. For instance, Fashion MNIST uses 28 x 28 images, which means each image has 784 pixels. We will need 10 qubits at least to represent the image, but we can represent a maximum of 1024 pixels. However, even if we don't wish to add any additional pixels, we still need to pad the vector with 0s to get a vector of 1024."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "923d91b9-8309-4442-8ddb-5974d533efff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2097152"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**int(np.ceil(np.log2(r_channel_data_flat.size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355d33c3-613e-4d64-b20f-86a652226db6",
   "metadata": {},
   "source": [
    "Here is our normalize(x) function. It takes in a vector as an input, and returns the 2-norm normalized vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6e3a0634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"Here is our normalize(x) function. It takes in a vector as an input, and returns the 2-norm normalized vector.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): \n",
    "            The image vector.\n",
    "\n",
    "    Returns:\n",
    "        (numpy.array): The 2-norm normalized vector.\n",
    "    \"\"\"\n",
    "    x = x.flatten() # First we flatten the image in case it is a 2d array\n",
    "    normalized_vector = x / np.linalg.norm(x) # Then we normalize the vector to 2-norm\n",
    "    normalized_vector = [*normalized_vector] # We then format to return an np.array\n",
    "\n",
    "    return normalized_vector # we return the normalized vector\n",
    "\n",
    "def de_normalize(normalized_vector, x):\n",
    "    \"\"\"Here is our denormalize(x) function. It takes in a 2-norm normalized vector as an input, and returns denormalized vector.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): \n",
    "            The 2-norm normalized vector.\n",
    "\n",
    "    Returns:\n",
    "        (numpy.array): The denormalized vector.\n",
    "    \"\"\"\n",
    "    return normalized_vector * np.linalg.norm(x.flatten()) # We return the denormalized vector by applying the inverse of the normalization factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0178a23e-f557-4ab0-a9fc-a84f68268658",
   "metadata": {},
   "source": [
    "We can see how these functions work in the cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0638fa04",
   "metadata": {},
   "source": [
    "## encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c2981d-ca21-4db6-a5bc-b42ecac9f840",
   "metadata": {},
   "source": [
    "Here is each channel before and after normalizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2bd8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('before normalize:')\n",
    "display(plt.imshow(red_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fc7165",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "red_normalized_vector = normalize(red_channel)\n",
    "#print(normalized_vector)\n",
    "print('after normalize:')\n",
    "plt.imshow(np.reshape(np.array(red_normalized_vector),red_channel.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f346ff-6e2e-490a-9d88-070b574095db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before normalize:')\n",
    "display(plt.imshow(green_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a74c2-6f39-4359-a747-adbd26ec16ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "green_normalized_vector = normalize(green_channel)\n",
    "#print(normalized_vector)\n",
    "print('after normalize:')\n",
    "plt.imshow(np.reshape(np.array(green_normalized_vector),green_channel.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbdd610-9fb7-4bae-9d48-c88af6490701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('before normalize:')\n",
    "display(plt.imshow(blue_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbb0022-0a9c-40c0-ac47-2742cbfabc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "blue_normalized_vector = normalize(blue_channel)\n",
    "#print(normalized_vector)\n",
    "print('after normalize:')\n",
    "plt.imshow(np.reshape(np.array(blue_normalized_vector),blue_channel.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e19504",
   "metadata": {},
   "source": [
    "## test encoding & decoding (1st task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375aaf89-e158-4079-8fe8-354892850dc2",
   "metadata": {},
   "source": [
    "The PQC we will be using to encode the image chunks will be RawFeatureVector. RawFeatureVector is a shallow PQC used for real-valued amplitude encoding. For a vector of size n, we will need a minimum of ceil(log2(n)) qubits, and must pad the vector to make sure it matches 2^(ceil(log2(n)) = n. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "1702fecf-dfd4-4bae-a5cc-e8459aef7d24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "This circuit has 2 qubits and 4 parameters.\n",
      "Below, you can see the circuit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">          ┌────────────┐┌───┐┌──────────┐┌───┐\n",
       "q_0: ─|0>─┤ U(π/2,0,0) ├┤ X ├┤ U(0,0,0) ├┤ X ├\n",
       "          ├────────────┤└─┬─┘└──────────┘└─┬─┘\n",
       "q_1: ─|0>─┤ U(π/2,0,0) ├──■────────────────■──\n",
       "          └────────────┘                      </pre>"
      ],
      "text/plain": [
       "          ┌────────────┐┌───┐┌──────────┐┌───┐\n",
       "q_0: ─|0>─┤ U(π/2,0,0) ├┤ X ├┤ U(0,0,0) ├┤ X ├\n",
       "          ├────────────┤└─┬─┘└──────────┘└─┬─┘\n",
       "q_1: ─|0>─┤ U(π/2,0,0) ├──■────────────────■──\n",
       "          └────────────┘                      "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = [0.5, 0.5, 0.5, 0.5]\n",
    "print(len(state))\n",
    "n = 2\n",
    "qc = RawFeatureVector(2**n)\n",
    "print(\"This circuit has \" + str(n) + \" qubits and \" + str(qc.num_parameters) + \" parameters.\")\n",
    "print(\"Below, you can see the circuit\")\n",
    "qc = qc.bind_parameters(state)\n",
    "qc.decompose(reps=20).draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f18652-e533-4052-ac07-717182d8a616",
   "metadata": {},
   "source": [
    "This is the simulate(circ) function, which takes a circuit, and extracts the statevector. We can use either the StatevectorSimulator or design a protocol that extracts this from measurements. \n",
    "\n",
    "Using the cell below, we can choose the best parameters for our simulator with respect to precision and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "13e5ed01-b4ce-4fc5-8323-06e36bef6f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CPU', 'GPU')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend = StatevectorSimulator(precision='double')\n",
    "backend.available_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e7f28b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiskit\n",
    "from qiskit import BasicAer\n",
    "\n",
    "def simulate(circ: qiskit.QuantumCircuit) -> dict:\n",
    "    \"\"\"This is the simulate(circ) function, which takes a circuit, and extracts the statevector.\n",
    "\n",
    "    Args:\n",
    "        circ (qiskit.QuantumCircuit): \n",
    "            The quantum circuit representing the encoded vector.\n",
    "\n",
    "    Returns:\n",
    "        (dict): The simulated statevector as a dict.\n",
    "    \"\"\"\n",
    "    backend = StatevectorSimulator(precision='double', device = \"GPU\", max_parallel_threads = 5) # First we initialize our bachend\n",
    "    job = execute(circ, backend,optimization_level=0) # We run the circuit on the simulator\n",
    "    result = job.result() # We extract the result from the job\n",
    "    state_vector = result.get_statevector() # We extract the state vector\n",
    "    \n",
    "    histogram = dict() # We initialize dictionary\n",
    "    for i in range(len(state_vector)): # We iterate over the length of the statevector\n",
    "        population = abs(state_vector[i]) ** 2 # We take the absolute value\n",
    "        histogram[i] = population # We append to the histogram\n",
    "    \n",
    "    return histogram # We return the histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57f9962-48c9-410e-af11-685693f1b059",
   "metadata": {},
   "source": [
    "We can now implement our encoding protocol. We will be using two functions for the encoder, and one function for the decoder. The Distributed Encoding Protocol is implemented by using encode_shallow which takes a chunk size, and an image, and internally runs encode_qiskit, which takes a chunk and the number of qubits, and returns the encoded PQC, which evidently gets added to a list which is returns by encode_shallow.\n",
    "\n",
    "Then we have the decoder, which takes a vector and the original image, and returns the decoded representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6c8605ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_chunk(x,num_qubit):\n",
    "    \"\"\"This is the encode_qiskit(x, num_qubit) function, which takes a vector and number of qubits, normalizes it, and returns its encoded representation as a PQC.\n",
    "\n",
    "    Args:\n",
    "        x (np.array): \n",
    "            The image vector.\n",
    "        num_qubit (int):\n",
    "            The number of qubits.\n",
    "\n",
    "    Returns:\n",
    "        (qc): The PQC from encoding the vector.\n",
    "    \"\"\"\n",
    "    normalized_vector = normalize(x) # We normalize the vector\n",
    "    qc = RawFeatureVector(2**num_qubit) # We initialize RFV\n",
    "    return qc.bind_parameters(normalized_vector) # We encode the vector and return the PQC\n",
    "\n",
    "def encode_distributed(n, image):\n",
    "    \"\"\"This is the encode_shallow(n, image) function, which takes an image and the chunk size, and encodes each chunk separately, and returns the list of PQCs.\n",
    "\n",
    "    Args:\n",
    "        n (int): \n",
    "            The chunk size.\n",
    "        image (np.array):\n",
    "            The image vector.\n",
    "\n",
    "    Returns:\n",
    "        (qc_list): The list of PQCs from encoding the vector chunks.\n",
    "    \"\"\"\n",
    "    qubit = int(np.ceil(np.log2(n))) # Getting the qubit number\n",
    "    print(\"Number of qubits is \" + str(qubit))\n",
    "    image = image.flatten() # Flatenning the 2D image\n",
    "    print(len(image))\n",
    "    state_chunks = [image[i * n:(i + 1) * n] for i in range((len(image) + n - 1) // n)]     # Discretizing the image into chunks of size n\n",
    "    print(\"Number of pixels in each chunk is \" + str(len(state_chunks[0])))\n",
    "    print(len(state_chunks))\n",
    "    chunk_avg = []\n",
    "    for i in range(len(state_chunks)):\n",
    "        chunk_avg.append(sum(state_chunks[i])/n)\n",
    "        \n",
    "    qc_list = [] # List of PQCs\n",
    "    counter = 0\n",
    "    for i in range(len(state_chunks)) : # Iterating over the chunks\n",
    "        if all(v == 0 for v in state_chunks[i]): # If an entire chunk is made of all 0s, then we simply append it, and do not need to encode it\n",
    "            qc_list.append(state_chunks[i])\n",
    "        else:\n",
    "            qc = encode_chunk(state_chunks[i], qubit) # Else, we pass it to encode_qiskit\n",
    "            qc_list.append(qc) # And append the qc to the list\n",
    "        if counter == 100000:\n",
    "            print(i)\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter+=1\n",
    "    print(len(qc_list))\n",
    "    return qc_list, chunk_avg # Lastly, we return the list of PQCs representing each chunk, and the chunk avg ratio\n",
    "\n",
    "def decode(histogram, data):\n",
    "    \"\"\"This is the decode(histogram, data) function, which takes a histogram and the original image, and returns the decoded vector.\n",
    "\n",
    "    Args:\n",
    "        histogram (dict): \n",
    "            The histogram representing the statevector.\n",
    "        data (np.array):\n",
    "            The original image vector\n",
    "\n",
    "    Returns:\n",
    "        (np.reshape(de_normalize(after_,data)[:784],data_shape)): The decoded image vector\n",
    "    \"\"\"\n",
    "    new_histogram = {} # First we initialize the histogram\n",
    "    for key in range(len(qc.parameters)): # Iterating over the keys\n",
    "        if key in histogram: # If a key is existing in the histogram\n",
    "            new_histogram[key] = histogram[key] # We simply append it (this protocol is for when we can only return non-zero amplitudes)\n",
    "        else: # Else if a key is not there\n",
    "            new_histogram[key] = 0 # We append a 0\n",
    "    #print(new_histogram)\n",
    "    after_ = np.array(list(new_histogram.values())) # We convert the histogram to a list of its values\n",
    "    return np.reshape(de_normalize(after_,data)[:784],data_shape) # And we return the denormalized vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380c9256-10cd-4216-88c5-9a989c210fc6",
   "metadata": {},
   "source": [
    "We will also be implementing two functions for evaluating the encoder with respect to depth and fidelity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "323b4bb1-1d22-4e0a-9a7a-ceaaa4002a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_gates(circuit: qiskit.QuantumCircuit) -> Dict[int, int]:\n",
    "    \"\"\"This is the count_gates(circuit: qiskit.QuantumCircuit) function, which takes a circuit and returns the number of gate operations with each number of qubits.\n",
    "\n",
    "    Args:\n",
    "        circuit (qiskit.QuantumCircuit): \n",
    "            The quantum circuit representing a vector.\n",
    "\n",
    "    Returns:\n",
    "        (Dict): the number of gate operations with each number of qubits.\n",
    "    \"\"\"\n",
    "    return Counter([len(gate[1]) for gate in circuit.data])\n",
    "\n",
    "def image_mse(image1,image2):\n",
    "    \"\"\"This is the image_mse(image1,image2) function, which takes two images and returns the mean squared error between the two.\n",
    "        Using sklearns mean squared error:\n",
    "        https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html\n",
    "\n",
    "    Args:\n",
    "        image1 (np.array): \n",
    "            An image vector.\n",
    "        image2 (np.array):\n",
    "            An image vector.\n",
    "            \n",
    "    Returns:\n",
    "        (mean_squared_error(image1, image2)): the mean squared error between the two images.\n",
    "    \"\"\"\n",
    "    return mean_squared_error(image1, image2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0622a6-f96e-481c-a30a-c1b16850185a",
   "metadata": {},
   "source": [
    "To put it all together, we will be using extract_image_re function, which takes an image, encodes it using the distributed encoding protocol, simulates it, extracts the overall encoded vector representing the image, denormalizes it, and returns the vector and histogram representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "38cd420c-bfb2-489c-852b-a2e7c1c5b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_re(data, n):\n",
    "    \"\"\"This is the extract_image_re(data) function, which takes an image and returns the decoded representation.\n",
    "\n",
    "    Args:\n",
    "        data (np.array): \n",
    "            The image vector.\n",
    "\n",
    "    Returns:\n",
    "        (image_re, hist_new): the the vector and histogram representation of the decoded vector.\n",
    "    \"\"\"\n",
    "    histogram = []\n",
    "    image_re = []\n",
    "    hist_new = []\n",
    "    circuit_list, chunk_avg = encode_distributed(n, data)\n",
    "    print(\"Encoding done...\")\n",
    "    for i in range(len(circuit_list)):\n",
    "        if all(v == 0 for v in circuit_list[i]):\n",
    "            histogram.append(circuit_list[i])\n",
    "        else:\n",
    "            histogram.append(simulate(circuit_list[i]))\n",
    "        if i>=1000 and i%1000==0:\n",
    "            print(str(i) + \" Circuits have been simulated.\")\n",
    "    \n",
    "    print(\"Simulation done...\")\n",
    "    \n",
    "    for i in range(len(histogram)):\n",
    "        if type(histogram[i]) is dict:\n",
    "            temp = list(histogram[i].values())\n",
    "            for j in range(n):\n",
    "                hist_new.append(chunk_avg[i]*temp[j])\n",
    "        else:\n",
    "            for j in range(n):\n",
    "                hist_new.append(histogram[i][j])\n",
    "    \n",
    "    print(\"Histogram done...\")\n",
    "    \n",
    "    print(len(hist_new))\n",
    "    global_avg = sum(data.flatten())/len(data.flatten())\n",
    "    hist_new = [hist_new[i] * int(global_avg) for i in range(len(hist_new))]\n",
    "    hist_new = hist_new / np.linalg.norm(hist_new)\n",
    "    \n",
    "    print(\"Histogram normalization done...\")\n",
    "    \n",
    "    sum_check = 0\n",
    "    for i in range(len(hist_new)):\n",
    "        sum_check+=hist_new[i]**2\n",
    "    print(sum_check)\n",
    "    \n",
    "    image_re = de_normalize(hist_new, Image_ghost_data)\n",
    "    \n",
    "    print(\"Histogram denormalization done...\")\n",
    "    \n",
    "    print(image_re)\n",
    "    return image_re, hist_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d68990d-9f64-4aa2-82a5-f8da6349cbef",
   "metadata": {},
   "source": [
    "Using the function below, we can now pass the extracted normalized channels, and create the RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4cdbb3f3-e4e2-4a7c-983a-e173f39078bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RGB_decoder(red_hist_vector, green_hist_vector, blue_hist_vector):\n",
    "    \"\"\"This is the RGB_decoder(red_hist_vector, green_hist_vector, blue_hist_vector) function, which takes three channels and returns the RGB image.\n",
    "\n",
    "    Args:\n",
    "        red_hist_vector (np.array): \n",
    "            The red channel normalized vector.\n",
    "        green_hist_vector (np.array): \n",
    "            The green channel normalized vector.\n",
    "        blue_hist_vector (np.array): \n",
    "            The blue channel normalized vector.\n",
    "    Returns:\n",
    "        (PIL RGB): The pillow RGB image.\n",
    "    \"\"\"\n",
    "    red_max = max(red_hist_vector)\n",
    "    green_max = max(green_hist_vector)\n",
    "    blue_max = max(blue_hist_vector)\n",
    "\n",
    "    red_hist = [red_hist_vector[i]*(255/red_max) for i in range(len(red_hist_vector))]\n",
    "    blue_hist = [blue_hist_vector[i]*(255/blue_max) for i in range(len(blue_hist_vector))]\n",
    "    green_hist = [green_hist_vector[i]*(255/green_max) for i in range(len(green_hist_vector))]\n",
    "\n",
    "    red_vector = np.array(red_hist).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "    green_vector = np.array(green_hist).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "    blue_vector = np.array(blue_hist).reshape(len(Image_ghost_data), len(Image_ghost_data[0]))\n",
    "\n",
    "    rgb = np.dstack((red_vector,green_vector,blue_vector))\n",
    "    print(rgb.shape)\n",
    "    \n",
    "    return Image.fromarray(np.array(rgb).astype(np.uint8), 'RGB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9eb0095-6d63-4378-8a3e-1356b6b20460",
   "metadata": {},
   "source": [
    "We will perform the protocol for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5236a514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Number of qubits is 6\n",
      "2073600\n",
      "Number of pixels in each chunk is 64\n",
      "32400\n",
      "32400\n",
      "Encoding done...\n",
      "1000 Circuits have been simulated.\n",
      "2000 Circuits have been simulated.\n",
      "3000 Circuits have been simulated.\n",
      "4000 Circuits have been simulated.\n",
      "5000 Circuits have been simulated.\n",
      "6000 Circuits have been simulated.\n",
      "7000 Circuits have been simulated.\n",
      "8000 Circuits have been simulated.\n",
      "9000 Circuits have been simulated.\n",
      "10000 Circuits have been simulated.\n",
      "11000 Circuits have been simulated.\n",
      "12000 Circuits have been simulated.\n",
      "13000 Circuits have been simulated.\n",
      "14000 Circuits have been simulated.\n",
      "15000 Circuits have been simulated.\n",
      "16000 Circuits have been simulated.\n",
      "17000 Circuits have been simulated.\n",
      "18000 Circuits have been simulated.\n",
      "19000 Circuits have been simulated.\n",
      "20000 Circuits have been simulated.\n",
      "21000 Circuits have been simulated.\n",
      "22000 Circuits have been simulated.\n",
      "23000 Circuits have been simulated.\n",
      "24000 Circuits have been simulated.\n",
      "25000 Circuits have been simulated.\n",
      "26000 Circuits have been simulated.\n",
      "27000 Circuits have been simulated.\n",
      "28000 Circuits have been simulated.\n",
      "29000 Circuits have been simulated.\n",
      "30000 Circuits have been simulated.\n",
      "31000 Circuits have been simulated.\n",
      "32000 Circuits have been simulated.\n",
      "Simulation done...\n",
      "Histogram done...\n",
      "2073600\n",
      "Histogram normalization done...\n",
      "1.0000000000002913\n",
      "Histogram denormalization done...\n",
      "[43.83369878 40.25699072 40.25699072 ... 26.75317593 26.75317593\n",
      " 26.75317593]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "dataset_red = [red_channel_data]\n",
    "print(len(dataset_red))\n",
    "\n",
    "for data in dataset_red:\n",
    "    red_image_re,red_hist_vector = extract_image_re(data, chunk_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae064aa0-ccac-401b-bd2a-b0d3a4a79ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Number of qubits is 6\n",
      "2073600\n",
      "Number of pixels in each chunk is 64\n",
      "32400\n",
      "32400\n",
      "Encoding done...\n",
      "1000 Circuits have been simulated.\n",
      "2000 Circuits have been simulated.\n",
      "3000 Circuits have been simulated.\n",
      "4000 Circuits have been simulated.\n",
      "5000 Circuits have been simulated.\n",
      "6000 Circuits have been simulated.\n",
      "7000 Circuits have been simulated.\n",
      "8000 Circuits have been simulated.\n",
      "9000 Circuits have been simulated.\n",
      "10000 Circuits have been simulated.\n",
      "11000 Circuits have been simulated.\n",
      "12000 Circuits have been simulated.\n",
      "13000 Circuits have been simulated.\n",
      "14000 Circuits have been simulated.\n",
      "15000 Circuits have been simulated.\n",
      "16000 Circuits have been simulated.\n",
      "17000 Circuits have been simulated.\n",
      "18000 Circuits have been simulated.\n",
      "19000 Circuits have been simulated.\n",
      "20000 Circuits have been simulated.\n",
      "21000 Circuits have been simulated.\n",
      "22000 Circuits have been simulated.\n",
      "23000 Circuits have been simulated.\n",
      "24000 Circuits have been simulated.\n",
      "25000 Circuits have been simulated.\n",
      "26000 Circuits have been simulated.\n",
      "27000 Circuits have been simulated.\n",
      "28000 Circuits have been simulated.\n",
      "29000 Circuits have been simulated.\n",
      "30000 Circuits have been simulated.\n",
      "31000 Circuits have been simulated.\n",
      "32000 Circuits have been simulated.\n",
      "Simulation done...\n",
      "Histogram done...\n",
      "2073600\n",
      "Histogram normalization done...\n",
      "1.0000000000010758\n",
      "Histogram denormalization done...\n",
      "[31.75456336 28.32428645 28.32428645 ... 18.40929015 18.40929015\n",
      " 18.40929015]\n"
     ]
    }
   ],
   "source": [
    "dataset_blue = [blue_channel_data]\n",
    "print(len(dataset_red))\n",
    "\n",
    "for data in dataset_blue:\n",
    "    blue_image_re,blue_hist_vector = extract_image_re(data, chunk_size)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e609a0da-e59b-4270-b332-e928e8f0b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Number of qubits is 6\n",
      "2073600\n",
      "Number of pixels in each chunk is 64\n",
      "32400\n",
      "32400\n",
      "Encoding done...\n",
      "1000 Circuits have been simulated.\n",
      "2000 Circuits have been simulated.\n",
      "3000 Circuits have been simulated.\n",
      "4000 Circuits have been simulated.\n",
      "5000 Circuits have been simulated.\n",
      "6000 Circuits have been simulated.\n",
      "7000 Circuits have been simulated.\n",
      "8000 Circuits have been simulated.\n",
      "9000 Circuits have been simulated.\n",
      "10000 Circuits have been simulated.\n",
      "11000 Circuits have been simulated.\n",
      "12000 Circuits have been simulated.\n",
      "13000 Circuits have been simulated.\n",
      "14000 Circuits have been simulated.\n",
      "15000 Circuits have been simulated.\n",
      "16000 Circuits have been simulated.\n",
      "17000 Circuits have been simulated.\n",
      "18000 Circuits have been simulated.\n",
      "19000 Circuits have been simulated.\n",
      "20000 Circuits have been simulated.\n",
      "21000 Circuits have been simulated.\n",
      "22000 Circuits have been simulated.\n",
      "23000 Circuits have been simulated.\n",
      "24000 Circuits have been simulated.\n",
      "25000 Circuits have been simulated.\n",
      "26000 Circuits have been simulated.\n",
      "27000 Circuits have been simulated.\n",
      "28000 Circuits have been simulated.\n",
      "29000 Circuits have been simulated.\n",
      "30000 Circuits have been simulated.\n",
      "31000 Circuits have been simulated.\n",
      "32000 Circuits have been simulated.\n",
      "Simulation done...\n",
      "Histogram done...\n",
      "2073600\n",
      "Histogram normalization done...\n",
      "1.0000000000001257\n",
      "Histogram denormalization done...\n",
      "[30.53692519 27.23818327 27.23818327 ... 21.99399208 21.99399208\n",
      " 21.99399208]\n"
     ]
    }
   ],
   "source": [
    "dataset_green = [green_channel_data]\n",
    "print(len(dataset_green))\n",
    "\n",
    "for data in dataset_green:\n",
    "    green_image_re,green_hist_vector = extract_image_re(data, chunk_size)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09831c9-3c5a-44d5-8a2a-068ae1931903",
   "metadata": {},
   "source": [
    "We can see the fidelity of the extracted vectors with the original vectors for each channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d55246f2-1a78-4029-a491-65bfe4ff620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722366432897372"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(red_hist_vector, red_normalized_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "9580d2cb-b5e0-485c-8ffb-2a4a1d1ccafe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9729221590395775"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(green_hist_vector, green_normalized_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "64e80825-c080-41db-95fa-cddae9fd4422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9727271466940925"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(blue_hist_vector, blue_normalized_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71288885-fd15-4641-b985-622c7f10a164",
   "metadata": {},
   "source": [
    "Now we can use RGB_decoder to create our RGB image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f19945f-39ea-48de-843d-b671f4b59990",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "RGB_decoder(red_hist_vector, green_hist_vector, blue_hist_vector)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01ba290fd8804f0bac31691741ebc3ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "190px"
      }
     },
     "070cdc5c615d4bf483e2c5b11fe102b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1f26de5771934d8fb58df3df649e843a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "145px"
      }
     },
     "277d4d23f80446d3aa94528f3618ad16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "grid_template_areas": "\n                                       \". . . . right \"\n                                        ",
       "grid_template_columns": "20% 20% 20% 20% 20%",
       "width": "100%"
      }
     },
     "2b6b80d0783943b89fde735dc3a9a62a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "2e2c6d423dc1487db867340064217e79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonStyleModel",
      "state": {}
     },
     "2ef793af6f1349bb8108c5899438e1a3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_73a2f4cf9c1e49d8941d8b460ff641f1",
       "style": "IPY_MODEL_503f3f1b3aa5447a9cea1b4a84fdba7c",
       "value": "<h5>Queue</h5>"
      }
     },
     "348175a3cf9c40358c34ef1f1d778a9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "3855fbd0a8fa4fd6acbf9a46ac2691bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_1f26de5771934d8fb58df3df649e843a",
       "style": "IPY_MODEL_348175a3cf9c40358c34ef1f1d778a9a",
       "value": "<h5>Backend</h5>"
      }
     },
     "38f479ae9b42400d9c255d73e4a541b2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_39b3f9d308974773a2293a510db1c415",
        "IPY_MODEL_3855fbd0a8fa4fd6acbf9a46ac2691bf",
        "IPY_MODEL_8adcff1111c44b5d9539521804e99d21",
        "IPY_MODEL_2ef793af6f1349bb8108c5899438e1a3",
        "IPY_MODEL_6343f27fe1b4456c9498e6caffee73dd"
       ],
       "layout": "IPY_MODEL_623391dce8aa4d99881fb619ee91bcfa"
      }
     },
     "39b3f9d308974773a2293a510db1c415": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_01ba290fd8804f0bac31691741ebc3ad",
       "style": "IPY_MODEL_6c695b636b314d40b812ba4fb28000f1",
       "value": "<h5>Job ID</h5>"
      }
     },
     "499f5ebcf75c42089bcc0477371728ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "503f3f1b3aa5447a9cea1b4a84fdba7c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "583b40093e4e4d4fa5c8f3c289ecce4a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "grid_area": "right",
       "padding": "0px 0px 0px 0px",
       "width": "70px"
      }
     },
     "5bdda78b8ec34c7b96ee1b721671132a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ButtonModel",
      "state": {
       "button_style": "primary",
       "description": "Clear",
       "layout": "IPY_MODEL_583b40093e4e4d4fa5c8f3c289ecce4a",
       "style": "IPY_MODEL_2e2c6d423dc1487db867340064217e79"
      }
     },
     "603f6fc75b7848cf9a3b56e8b1429690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "95px"
      }
     },
     "623391dce8aa4d99881fb619ee91bcfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0px 0px 0px 37px",
       "width": "600px"
      }
     },
     "6343f27fe1b4456c9498e6caffee73dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_2b6b80d0783943b89fde735dc3a9a62a",
       "style": "IPY_MODEL_070cdc5c615d4bf483e2c5b11fe102b2",
       "value": "<h5>Message</h5>"
      }
     },
     "6c695b636b314d40b812ba4fb28000f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "73a2f4cf9c1e49d8941d8b460ff641f1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "width": "70px"
      }
     },
     "820c61043bb644788ab00ea0b8253118": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "8adcff1111c44b5d9539521804e99d21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_603f6fc75b7848cf9a3b56e8b1429690",
       "style": "IPY_MODEL_820c61043bb644788ab00ea0b8253118",
       "value": "<h5>Status</h5>"
      }
     },
     "936b830540cf4bcf8ff862f87228362b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "margin": "0px 0px 10px 0px"
      }
     },
     "a0efcd1dd88d48bdad72a537582e9749": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_936b830540cf4bcf8ff862f87228362b",
       "style": "IPY_MODEL_499f5ebcf75c42089bcc0477371728ff",
       "value": "<p style='font-family: IBM Plex Sans, Arial, Helvetica, sans-serif; font-size: 20px; font-weight: medium;'>Circuit Properties</p>"
      }
     },
     "cf6b43eaea1148918061eeeaec25c185": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "GridBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5bdda78b8ec34c7b96ee1b721671132a"
       ],
       "layout": "IPY_MODEL_277d4d23f80446d3aa94528f3618ad16"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
